import streamlit as st
import pandas as pd
import joblib
import numpy as np
from scipy import stats
from sklearn.preprocessing import OrdinalEncoder

# Function to preprocess data
def preprocess_data(data, is_dataframe=False):
    if not is_dataframe:
        # Load the data from CSV
        data_frame = pd.read_csv(data)
    else:
        # Assume data is already a DataFrame
        data_frame = data.copy()
    
    # Cast 'Time' to integer
    data_frame['Time'] = data_frame['Time'].astype(int)
    
    # Reshape and encode the 'Time' feature
    time_encoded = OrdinalEncoder().fit_transform(data_frame[['Time']])
    data_frame['Time_Encoded'] = time_encoded
    
    # Drop the original 'Time' column
    data_frame = data_frame.drop(columns=['Time'])
    
    # Load the scaler
    scaler = joblib.load('models/amount_scaler.joblib')
    
    # Scale the 'Amount' column and apply Box-Cox transformation
    data_frame['Amount_Scaled'] = scaler.transform(data_frame[['Amount']])
    
    # Apply Box-Cox transformation to the 'Amount' column with the given lambda value
    boxcox_lambda = -0.04497254555023551
    data_frame['Amount_BoxCox'] = stats.boxcox(data_frame['Amount'] + 1, lmbda=boxcox_lambda)
    
    # Drop the 'Amount' and 'Amount_Scaled' columns
    data_frame = data_frame.drop(columns=['Amount', 'Amount_Scaled'])
    
    return data_frame

# Function to load the model dynamically
def load_model(model_name):
    model_path = f'models/{model_name}.joblib'  # Use the model_name variable correctly
    return joblib.load(model_path)

# Function to make predictions
def make_prediction(model, X):
    return model.predict(X)  # or model.predict_proba(X) for probability predictions

# Reset functionality
if st.sidebar.button('Reset'):
    st.session_state.clear()

# Streamlit app
st.title('FindDefault: Prediction of Credit Card Fraud')

# Sidebar for file upload, model selection, and prediction
st.sidebar.header("Upload & Settings")

# Instructions moved to the sidebar
st.write("""
    #### Instructions
    1. **Upload a CSV file**: Click on the file uploader to select your CSV file.
    2. **Data Structure Required**:
       - **'Time'**: Time elapsed since the first transaction in seconds.
       - **'V1' to 'V28'**: Anonymized features generated by PCA.
       - **'Amount'**: Transaction amount (will be transformed).
    3. **Select a model**: Use the radio buttons to choose a model.
    4. **Click Predict**: After uploading the file and selecting a model, click on the Predict button to process the data.
    5. **Download Predictions**: You will be able to download the processed data with predictions.
""")

# Model selection with radio buttons
model_selection = st.sidebar.selectbox(
    "Select Model",
    ["xgb_best1_v1", "xgb_base_v1", "lgbm_best_v1", "rf_base_v1", "dt_base_v1", "logreg_base_v1", "gnb_base_v1", "knn_base_v1", "svm_base_v1"]  # Replace with actual model names
)

# Model descriptions
model_descriptions = {
    "xgb_best1_v1": "XGBoost model with tuned hyperparameters. Suitable for high performance and large datasets.",
    "xgb_base_v1": "Base XGBoost model. Useful as a baseline model.",
    "lgbm_best_v1": "LightGBM model with tuned hyperparameters. Known for speed and efficiency with large datasets.",
    "rf_base_v1": "Random Forest model. An ensemble of decision trees, useful for general-purpose classification.",
    "dt_base_v1": "Decision Tree model. Provides clear interpretability but may overfit.",
    "logreg_base_v1": "Logistic Regression model. Good for understanding feature impacts and probabilities.",
    "gnb_base_v1": "Gaussian Naive Bayes model. Assumes feature independence, suitable for probabilistic predictions.",
    "knn_base_v1": "K-Nearest Neighbors model. Simple yet effective for small to medium-sized datasets.",
    "svm_base_v1": "Support Vector Machine model. Effective in high-dimensional spaces and for clear margin separation."
}

st.sidebar.write(f"### Model Description:\n{model_descriptions.get(model_selection, 'No description available for the selected model.')}")

# File upload
uploaded_file = st.sidebar.file_uploader("Choose a CSV file", type="csv")

if uploaded_file is not None:
    # Save the uploaded file to a temporary location
    with open("temp_uploaded_file.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # Process data
    processed_df = preprocess_data("temp_uploaded_file.csv")
    
    if processed_df is not None:
        st.write(f"### Processed Data_{model_selection}")
        st.write(processed_df.head())
    
        # Add prediction functionality based on selected model
        if st.sidebar.button('Predict'):
            model = load_model(model_selection)  # Load the selected model
            if model:
                try:
                    predictions = make_prediction(model, processed_df)  # Make predictions
                    processed_df['Prediction'] = predictions
                    # Save predictions to a CSV file with dynamic model name
                    output_file = f"predictions_{model_selection}.csv"
                    processed_df.to_csv(output_file, index=False)
                    st.write("### Predictions")
                    st.write(processed_df.head())
                    st.download_button(
                        label="Download Predictions File",
                        data=processed_df.to_csv(index=False),
                        file_name=output_file,
                        mime="text/csv"
                    )
                except Exception as e:
                    st.error(f"Error making predictions: {e}")
            else:
                st.error("Failed to load the model. Please check the model file.")
    else:
        st.error("Data processing failed. Please ensure the file is in the correct format.")
else:
    st.write("Please upload a CSV file.")

# Styling and Layout Adjustments
st.markdown("""
    <style>
        .css-18e3th9 {
            padding: 2rem;
        }
        .css-1y4n4ju {
            margin-top: 2rem;
        }
        .css-1r7j9sv {
            border-bottom: 2px solid #f0f0f0;
            margin-bottom: 2rem;
        }
    </style>
    """, unsafe_allow_html=True)