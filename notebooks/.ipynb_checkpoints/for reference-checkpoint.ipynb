{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f56ae6",
   "metadata": {},
   "source": [
    "# Lets load the processed data and objects to Build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64c7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\hp\\Documents\\find-default\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# check Current Workign Directroy \n",
    "\n",
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2925296",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'\\Users\\hp\\Documents\\find-default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57c9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the data and scaler\n",
    "X_train = joblib.load('data/processed-data/X_train.pkl')\n",
    "X_val = joblib.load('data/processed-data/X_val.pkl')\n",
    "y_train = joblib.load('data/processed-data/y_train.pkl')\n",
    "y_val = joblib.load('data/processed-data/y_val.pkl')\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "X_train_resampled = joblib.load('data/processed-data/X_train_resampled.pkl')\n",
    "y_train_resampled = joblib.load('data/processed-data/y_train_resampled.pkl')\n",
    "X_train_smote = joblib.load('data/processed-data/X_train_smote.pkl')\n",
    "y_train_smote = joblib.load('data/processed-data/y_train_smote.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ddd00",
   "metadata": {},
   "source": [
    "# Model 1 - LOGISTIC REGRESSION - logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c129e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/logreg_base_v1.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "# Initialize the model\n",
    "logreg_base = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_base.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data & probabilities for ROC_AUC\n",
    "y_val_pred_base = logreg_base.predict(X_val)\n",
    "y_val_proba_base = logreg_base.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(logreg_base, 'models/logreg_base_v1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193cff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[45477    21]\n",
      " [   25    46]]\n",
      "Classufication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45498\n",
      "           1       0.69      0.65      0.67        71\n",
      "\n",
      "    accuracy                           1.00     45569\n",
      "   macro avg       0.84      0.82      0.83     45569\n",
      "weighted avg       1.00      1.00      1.00     45569\n",
      "\n",
      "F1 Score (weighted) : 0.9989759341728442\n",
      "ROC AUC Score: 0.9272442868561317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_val_pred_base)\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba_base)\n",
    "val_f1_score = f1_score(y_val, y_val_pred_base, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_base, output_dict=True)\n",
    "\n",
    "print(\"Logistic Regression - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_base))\n",
    "\n",
    "print(\"Classufication Report\")\n",
    "print(classification_report(y_val, y_val_pred_base))\n",
    "\n",
    "print(\"F1 Score (weighted) :\", val_f1_score)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbdb971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logreg_base_metrics_v1.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "logreg_base_metrics = {'accuracy': accuracy, 'roc_auc': roc_auc, 'classification_report': report, 'f1_score': f1_score}\n",
    "joblib.dump(logreg_base_metrics, 'models/logreg_base_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572102cd",
   "metadata": {},
   "source": [
    "## Model 2 - Undersampling - Log_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930039b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logreg_rus_v1.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression for Undersampled Data\n",
    "logreg_rus = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_rus.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on validation data & probabilities for ROC_AUC\n",
    "y_val_pred_rus = logreg_rus.predict(X_val)\n",
    "y_val_proba_rus = logreg_rus.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(logreg_base, 'models/logreg_rus_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9456e552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Undersampling - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[44583   915]\n",
      " [   10    61]]\n",
      "Classufication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     45498\n",
      "           1       0.06      0.86      0.12        71\n",
      "\n",
      "    accuracy                           0.98     45569\n",
      "   macro avg       0.53      0.92      0.55     45569\n",
      "weighted avg       1.00      0.98      0.99     45569\n",
      "\n",
      "F1 Score (weighted)  : 0.9883720767317283\n",
      "ROC AUC Score: 0.9644627623316053\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_logreg_rus = accuracy_score(y_val, y_val_pred_rus)\n",
    "roc_auc_logreg_rus = roc_auc_score(y_val, y_val_proba_rus)\n",
    "f1_score_logreg_rus = f1_score(y_val, y_val_pred_rus, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_rus, output_dict=True)\n",
    "\n",
    "print(\"Logistic Regression - Undersampling - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_rus))\n",
    "\n",
    "print(\"Classufication Report\")\n",
    "print(classification_report(y_val, y_val_pred_rus))\n",
    "\n",
    "print(\"F1 Score (weighted)  :\", f1_score_logreg_rus)\n",
    "print(\"ROC AUC Score:\", roc_auc_logreg_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4d924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logreg_rus_metrics_v1.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "logreg_base_metrics = {'accuracy': accuracy_logreg_rus, 'roc_auc': roc_auc_logreg_rus, 'classification_report': report, 'f1_score': f1_score_logreg_rus}\n",
    "joblib.dump(logreg_base_metrics, 'models/logreg_rus_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece6c0d",
   "metadata": {},
   "source": [
    "# Model 3 - Logistic Regression - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7eb486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/log_reg_smote_v1.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistic Regression on SMOTE data\n",
    "log_reg_smote = LogisticRegression(max_iter=1000)\n",
    "log_reg_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on validation data\n",
    "y_val_pred_smote = log_reg_smote.predict(X_val)\n",
    "y_val_proba_smote = log_reg_smote.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(log_reg_smote, 'models/log_reg_smote_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0303fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Undersampling - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[44525   973]\n",
      " [   10    61]]\n",
      "Classufication Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     45498\n",
      "           1       0.06      0.86      0.11        71\n",
      "\n",
      "    accuracy                           0.98     45569\n",
      "   macro avg       0.53      0.92      0.55     45569\n",
      "weighted avg       1.00      0.98      0.99     45569\n",
      "\n",
      "F1 Score (weighted)  : 0.9877127387399042\n",
      "ROC AUC Score: 0.9619166049088057\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_logreg_smote = accuracy_score(y_val, y_val_pred_smote)\n",
    "roc_auc_logreg_smote = roc_auc_score(y_val, y_val_proba_smote)\n",
    "f1_score_logreg_smote = f1_score(y_val, y_val_pred_smote, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_smote, output_dict=True)\n",
    "\n",
    "print(\"Logistic Regression - Undersampling - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_smote))\n",
    "\n",
    "print(\"Classufication Report\")\n",
    "print(classification_report(y_val, y_val_pred_smote))\n",
    "\n",
    "print(\"F1 Score (weighted)  :\", f1_score_logreg_smote)\n",
    "print(\"ROC AUC Score:\", roc_auc_logreg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54753a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logreg_smote_metrics_v1.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "logreg_smote_metrics = {'accuracy': accuracy_logreg_smote, 'roc_auc': roc_auc_logreg_smote, 'classification_report': report, 'f1_score': f1_score_logreg_smote}\n",
    "joblib.dump(logreg_base_metrics, 'models/logreg_smote_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cd7f7",
   "metadata": {},
   "source": [
    "# Model 4 - Naive Bayes - Base\n",
    "\n",
    "Features in our dataframe are continious hence Gaussian NB is the best choice compared to other NB Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daceaf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_base_v1.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "# Initialize the model\n",
    "gnb_base = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "gnb_base.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data & probabilities for ROC_AUC\n",
    "y_val_pred_base = gnb_base.predict(X_val)\n",
    "y_val_proba_base = gnb_base.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(gnb_base, 'models/gnb_base_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183bd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[45400    98]\n",
      " [   39    32]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45498\n",
      "           1       0.25      0.45      0.32        71\n",
      "\n",
      "    accuracy                           1.00     45569\n",
      "   macro avg       0.62      0.72      0.66     45569\n",
      "weighted avg       1.00      1.00      1.00     45569\n",
      "\n",
      "F1 Score (weighted) : 0.9974338370892074\n",
      "ROC AUC Score: 0.9272442868561317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_gnb_base = accuracy_score(y_val, y_val_pred_base)\n",
    "roc_auc_gnb_base = roc_auc_score(y_val, y_val_proba_base)\n",
    "f1_score_gnb_base = f1_score(y_val, y_val_pred_base, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_base, output_dict=True)\n",
    "\n",
    "print(\"Gaussian Naive Bayes - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_base))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_base))\n",
    "\n",
    "print(\"F1 Score (weighted) :\", f1_score_gnb_base)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a32387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_base_metrics_v1.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "gnb_base_metrics = {'accuracy': accuracy_gnb_base, 'roc_auc': roc_auc_gnb_base, 'classification_report': report, 'f1_score': f1_score_gnb_base}\n",
    "joblib.dump(gnb_base_metrics, 'models/gnb_base_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad51a1",
   "metadata": {},
   "source": [
    "# Model 5 - Gaussian NB - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc0f0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_rus_v1.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Gaussian Naive Bayes model on the undersampled data\n",
    "gnb_rus = GaussianNB()\n",
    "gnb_rus = gnb_rus.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on validation data\n",
    "y_val_pred_gnb_rus = gnb_rus.predict(X_val)\n",
    "y_val_proba_gnb_rus = gnb_rus.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(gnb_rus, 'models/gnb_rus_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364f6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[45338   160]\n",
      " [   33    38]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45498\n",
      "           1       0.19      0.54      0.28        71\n",
      "\n",
      "    accuracy                           1.00     45569\n",
      "   macro avg       0.60      0.77      0.64     45569\n",
      "weighted avg       1.00      1.00      1.00     45569\n",
      "\n",
      "F1 Score (weighted) :, 0.9967614959638402\n",
      "ROC AUC Score: 0.9272442868561317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_gnb_rus = accuracy_score(y_val, y_val_pred_gnb_rus)\n",
    "roc_auc_gnb_rus = roc_auc_score(y_val, y_val_proba_gnb_rus)\n",
    "f1_score_gnb_rus = f1_score(y_val, y_val_pred_gnb_rus, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_gnb_rus, output_dict=True)\n",
    "\n",
    "print(\"Gaussian Naive Bayes - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_gnb_rus))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_gnb_rus))\n",
    "\n",
    "print(f\"F1 Score (weighted) :, {f1_score_gnb_rus}\")\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1bb761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_rus_metrics_v1.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "gnb_rus_metrics = {'accuracy': accuracy_gnb_rus, 'roc_auc': roc_auc_gnb_rus, 'classification_report': report, 'f1_score': f1_score_gnb_rus}\n",
    "joblib.dump(gnb_rus_metrics, 'models/gnb_rus_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a237e0",
   "metadata": {},
   "source": [
    "# Model 6 - Gaussian NB - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712a998d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_smote_v1.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Gaussian Naive Bayes model on the undersampled data\n",
    "gnb_smote = GaussianNB()\n",
    "gnb_smote = gnb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on validation data\n",
    "y_val_pred_gnb_smote = gnb_smote.predict(X_val)\n",
    "y_val_proba_gnb_smote = gnb_smote.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(gnb_smote, 'models/gnb_smote_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "240f428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - Validation Performance:\n",
      "Confusion Matrix:\n",
      "[[44525   973]\n",
      " [   10    61]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     45498\n",
      "           1       0.06      0.86      0.11        71\n",
      "\n",
      "    accuracy                           0.98     45569\n",
      "   macro avg       0.53      0.92      0.55     45569\n",
      "weighted avg       1.00      0.98      0.99     45569\n",
      "\n",
      "F1 Score (weighted) : 0.9877127387399042\n",
      "ROC AUC Score: 0.9272442868561317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_gnb_smote = accuracy_score(y_val, y_val_pred_smote)\n",
    "roc_auc_gnb_smote = roc_auc_score(y_val, y_val_proba_smote)\n",
    "f1_score_gnb_smote = f1_score(y_val, y_val_pred_smote, average='weighted')\n",
    "report = classification_report(y_val, y_val_pred_smote, output_dict=True)\n",
    "\n",
    "print(\"Gaussian Naive Bayes - Validation Performance:\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_smote))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_smote))\n",
    "\n",
    "print(\"F1 Score (weighted) :\", f1_score_gnb_smote)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26fc0238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gnb_smote_metrics_v1.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save evaluation metrics\n",
    "gnb_smote_metrics = {'accuracy': accuracy_gnb_smote, 'roc_auc': roc_auc_gnb_smote, 'classification_report': report, 'f1_score': f1_score_gnb_smote}\n",
    "joblib.dump(gnb_smote_metrics, 'models/gnb_smote_metrics_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddec82",
   "metadata": {},
   "source": [
    "# Model 7 - Decission Tree - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and build model\n",
    "dt_base = DecisionTreeClassifier(random_state=42)\n",
    "dr_base = dt_base.fit(X_train, y_train)\n",
    "\n",
    "# predict on validation data & probabilities for roc_auc \n",
    "y_val_pred_dt_base = dt_base.predict(X_val)\n",
    "y_val_prob_dt_base = dt_base.predict_proba(X_val)[:,1]\n",
    "\n",
    "# save the model\n",
    "joblib.dump(dt_base, 'models/dt_base_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60631862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e222ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c81855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e806c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42a652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35082a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf25207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fbdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712c1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c061c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60005d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd6101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbe6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cefd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
